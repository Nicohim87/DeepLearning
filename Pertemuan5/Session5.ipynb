{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tf.data.TextLineDataset('ind2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 22\n",
    "MAX_TOKENS = 20000\n",
    "ENG_SEQ_LEN = 32\n",
    "INA_SEQ_LEN = 32\n",
    "EMBEDDING_DIM = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_vec_layer = tf.keras.layers.TextVectorization(\n",
    "    standardize = \"lower_and_strip_punctuation\",\n",
    "    max_tokens = MAX_TOKENS,\n",
    "    output_mode = 'int',\n",
    "    output_sequence_length = ENG_SEQ_LEN\n",
    ")\n",
    "\n",
    "indonesian_vec_layer = tf.keras.layers.TextVectorization(\n",
    "    standardize = \"lower_and_strip_punctuation\",\n",
    "    max_tokens = MAX_TOKENS,\n",
    "    output_mode = 'int',\n",
    "    output_sequence_length = INA_SEQ_LEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text):\n",
    "    text = tf.strings.split(text, '\\t')\n",
    "    input_1 = text[:1]\n",
    "    input_2 = 'starttoken ' + text[1:2] + ' endtoken'\n",
    "    return input_1, input_2\n",
    "\n",
    "def vectorize(text):\n",
    "    text = tf.strings.split(text, '\\t')\n",
    "    input_1 = text[:1]\n",
    "    input_start = 'starttoken ' + text[1:2]\n",
    "    input_end = text[1:2] + ' endtoken'\n",
    "    return {\n",
    "        'input_1' : english_vec_layer(input_1),\n",
    "        'input_2' : indonesian_vec_layer(input_start)\n",
    "    }, indonesian_vec_layer(input_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted = df.map(split_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_data = splitted.map(lambda x, y: x)\n",
    "english_vec_layer.adapt(eng_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ina_data = splitted.map(lambda x, y: y)\n",
    "indonesian_vec_layer.adapt(ina_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.map(vectorize)\n",
    "data = data.shuffle(200).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "data_len = sum(1 for _ in data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_len = sum(1 for _ in data)\n",
    "train = df.take(int(data_len * 0.9))\n",
    "validate = df.skip(int(data_len * 0.9))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
