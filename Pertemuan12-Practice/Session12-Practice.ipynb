{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"Dataset/Logos\"\n",
    "IMG_SIZE = (100, 100)\n",
    "\n",
    "images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(DATASET_PATH):\n",
    "    img = tf.keras.utils.load_img(os.path.join(DATASET_PATH, filename), target_size = IMG_SIZE)\n",
    "    img = tf.keras.utils.img_to_array(img)\n",
    "    img /= 255\n",
    "    images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = images[:10]\n",
    "x_test = images[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 25\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "IMG_ORIGINAL_SIZE = x_train[0].shape\n",
    "IMG_SIZE = IMG_ORIGINAL_SIZE[0]*IMG_ORIGINAL_SIZE[1]*IMG_ORIGINAL_SIZE[2]\n",
    "\n",
    "HIDDEN_DIM = 512\n",
    "LATENT_DIM = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(tf.keras.Model):\n",
    "    def __init__(self, dim, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        \n",
    "        h_dim = dim[0]\n",
    "        z_dim = dim[1]\n",
    "        \n",
    "        self.fc1 = tf.keras.layers.Dense(h_dim, activation = 'relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(z_dim)\n",
    "        self.fc3 = tf.keras.layers.Dense(z_dim)\n",
    "        \n",
    "        self.fc4 = tf.keras.layers.Dense(z_dim)\n",
    "        self.fc5 = tf.keras.layers.Dense(IMG_SIZE)\n",
    "        \n",
    "        self.encode_batch_norm = tf.keras.layers.BatchNormalization()\n",
    "        self.decode_batch_norm = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "    def encode(self, input):\n",
    "        x = self.encode_batch_norm(input)\n",
    "        h = self.fc1(x)\n",
    "        return self.fc2(x), self.fc3(x)\n",
    "    \n",
    "    def decode_logits(self, x):\n",
    "        h = self.fc4(x)\n",
    "        h = self.fc5(h)\n",
    "        return self.decode_batch_norm(h)\n",
    "    \n",
    "    def decode(self, x):\n",
    "        return tf.nn.sigmoid(self.decode_logits(x))\n",
    "    \n",
    "    def reparameterize(self, mu, sigma):\n",
    "        std = tf.exp(sigma / 2)\n",
    "        eps = tf.random.normal(std.shape)\n",
    "        return mu + eps*std\n",
    "    \n",
    "    def call(self, x):\n",
    "        mu, sigma = self.encode(x)\n",
    "        z = self.reparameterize(mu, sigma)\n",
    "        logits = self.decode_logits(z)\n",
    "        \n",
    "        return logits, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Conda\\envs\\TensorFlow\\Lib\\site-packages\\keras\\src\\layers\\layer.py:391: UserWarning: `build()` was called on layer 'vae', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"vae\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"vae\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = VAE([HIDDEN_DIM, LATENT_DIM])\n",
    "model.build(input_shape = (BATCH_SIZE, IMG_SIZE))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "dataset = dataset.shuffle(BATCH_SIZE * 5).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_hist = []\n",
    "kl_div_hist = []\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    for x in dataset:\n",
    "        print(\"Processing batch...\")\n",
    "        data = tf.reshape(x, [-1, IMG_SIZE])\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits, mu, sigma = model(x)\n",
    "            \n",
    "            recon_loss = tf.nn.sigmoid_cross_entropy_with_logits(x, logits)\n",
    "            recon_loss = tf.reduce_sum(recon_loss) / BATCH_SIZE\n",
    "            \n",
    "            kl_div = 0.5 * tf.reduce_sum(1.0 + sigma - tf.square(mu) - tf.exp(sigma), axis=1)\n",
    "            kl_div = tf.reduce_mean(kl_div)\n",
    "            \n",
    "            loss = tf.reduce_mean(kl_div + recon_loss)\n",
    "            \n",
    "        gradient = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
    "        \n",
    "        loss_hist.append(loss)\n",
    "        kl_div_hist.append(kl_div)\n",
    "        \n",
    "    print(f\"Epoch #{e+1} | Loss = {recon_loss} | kl_div = {kl_div} | loss = {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(1, 2, 1)\n",
    "plt.plot(loss_hist)\n",
    "plt.title(\"Loss\")\n",
    "plt.ylabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.subplots(2, 2, 1)\n",
    "plt.plot(kl_div)\n",
    "plt.title(\"Kl Divergence\")\n",
    "plt.ylabel(\"Epochs\")\n",
    "plt.ylabel(\"Kl_Div\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(z):\n",
    "    out = model.decode(z)\n",
    "    out = tf.reshape(out, (-1, IMG_ORIGINAL_SIZE))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = model.encode(x_test.reshape(-1, IMG_SIZE))\n",
    "z = model.reparameterize(mu, sigma)\n",
    "recon_img = get_img(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplot(nrows = 2, ncols = len(x_test))\n",
    "for i in len(x_test):\n",
    "    ax[0, i].imshow(x_test[i])\n",
    "    ax[0, i].get_xaxis().set_visible(False)\n",
    "    ax[0, i].get_yaxis().set_visible(False)\n",
    "    \n",
    "    ax[1, i].imshow(recon_img[i])\n",
    "    ax[1, i].get_xaxis().set_visible(False)\n",
    "    ax[1, i].get_yaxis().set_visible(False)\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
